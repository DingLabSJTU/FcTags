{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fluoro-changing Tags Based on DNA Strand Displacement Enable Highly Multiplexed Protein Imaging\n",
    "## Overview of FcTags\n",
    "Fluoro-changing Tags (FcTags) are capable of generating exponentially scalable antibody tags for spatial proteomics imaging with easily accessible equipment and reagent. To decode proteins from FcTag-based images, we developed an AI algorithm platform here. The algorithm accurately aligns fluorescent images captured at different time points, and decodes proteins via two unique algorithms called `Subtraction` and `Linear unmixing`. The step-by-step operations and important notes can be found in the corresponding section of each algorithm file.\n",
    "\n",
    "## Computer hardware (optional)\n",
    "- Computer workstation equipped with an AMD Ryzen 5975WX CPU\n",
    "- NVIDIA RTX 3090 graphics processing card\n",
    "\n",
    "## Environmental setup\n",
    "See pyproject.toml file for library version and various dependencies. Here are the steps you need to take to install the python environment:\n",
    "\n",
    "### 1. Install Jupyter Notebook 7.x (or Python 3.x)\n",
    "The algorithm is crafted in Python and executed within Jupyter Notebook.  To execute the files, you have the option to install either `Python 3.x` or `Jupyter Notebook 7.x`.\n",
    "\n",
    "To install Jupyter Notebook 7.x, you can download it from the [official Jupyter website](https://jupyter.org/).\n",
    "\n",
    "To install Python 3.x, you can download it from the [official Python website](https://www.python.org/).\n",
    "\n",
    "### 2. Update `pip` (optional)\n",
    "It's a good practice to keep `pip` up to date. Open a terminal (or command prompt) and run the following command:\n",
    "\n",
    "```bash\n",
    "python -m pip install --upgrade pip\n",
    "```\n",
    "\n",
    "### 3. Install Required Libraries\n",
    "To install the necessary packages (`numpy`, `PIL`, `cv2`, `pandas`), run the following command in your terminal or command prompt:\n",
    "\n",
    "```bash\n",
    "pip install numpy scipy scikit-image pandas\n",
    "```\n",
    "\n",
    "### 4. Verify Installation\n",
    "After installation, you can verify that the libraries are installed correctly by running this Python script:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"cv2 version: {cv2.__version__}\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "```\n",
    "\n",
    "This script will print the installed versions of the libraries. If you see the version numbers printed without any errors, the libraries were installed successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preparing input images\n",
    "Image obtained at time point 1 (T1)\n",
    "- `T1_DAPI`: DAPI channel obtained at T1 (0 min in this study);\n",
    "- `T1_AF488`: AF488 channel obtained at T1 (0 min in this study);\n",
    "- `T1_Cy3`: Cy3 channel obtained at T1 (0 min in this study);\n",
    "- `T1_Cy5`: Cy5 channel obtained at T1 (0 min in this study);<br>\n",
    "\n",
    "Image obtained at time point 2 (T2)\n",
    "- `T2_DAPI`: DAPI channel obtained at T2 (15 min in this study);\n",
    "- `T2_AF488`: AF488 channel obtained at T2 (15 min in this study);\n",
    "- `T2_Cy3`: Cy3 channel obtained at T2 (15 min in this study);\n",
    "- `T2_Cy5`: Cy5 channel obtained at T2 (15 min in this study);<br>\n",
    "\n",
    "Image obtained at time point 3 (T3)\n",
    "- `T3_DAPI`: DAPI channel obtained at T3 (30 min in this study);\n",
    "- `T3_AF488`: AF488 channel obtained at T3 (30 min in this study);\n",
    "- `T3_Cy3`: Cy3 channel obtained at T3 (30 min in this study);\n",
    "- `T3_Cy5`: Cy5 channel obtained at T3 (30 min in this study);<br>\n",
    "\n",
    "Notes：\n",
    "- All images are captured under identical microscopic parameters.\n",
    "- The DAPI channel can be replaced by the merged image of AF488, Cy3 and Cy5 channel.\n",
    "- Prior to merging multiple image channels, it is crucial to address the variation in grayscale values that arise when different pseudocolors are directly converted to grayscale images. To ensure consistency and accurate representation of data, all channels should be converted to grayscale mode before the merging process. This standardization step is essential because different colors, when transformed to grayscale, can produce varying levels of brightness and contrast, potentially leading to misinterpretation of the relative intensities across channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Image registration\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following Python code uses the `SimpleITK` library to call the `elastix` and `transformix` tools for rigid registration. Before running the code, please ensure that `elastix` and `transformix` are correctly installed, and the directories containing their executable files are added to the system’s environment variables so that the code can call them properly. In addition, you need to install the following modules in the notebook environment using the following commands: `pip install SimpleITK` ; `pip install SimpleITK-SimpleElastix`.\n",
    "- The main function of the code is to align fluorescence images (DAPI, AF488, Cy3, and Cy5 channels) at different time points with a spatial reference (e.g., the image obtained at time point 1) to correct positional deviations between the images. It contains two main steps.\n",
    "- `Step 1: registration of DAPI images`: rigidly register the DAPI images at different time points (T2_DAPI, T3_DAPI) with the reference image (T1_DAPI), and record the transformation parameters during the registration process.\n",
    "- `Step 2: application of transformation parameters`: apply the transformation parameters for DAPI registration to other channel images (AF488, Cy3, Cy5) obtained at the same time point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registration and transformation completed.\n"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "\n",
    "\n",
    "def rigid_registration(fixed_image, moving_image):\n",
    "    \"\"\"\n",
    "    Perform rigid registration between fixed and moving images.\n",
    "    :param fixed_image: Fixed image for registration.\n",
    "    :param moving_image: Moving image to be registered to the fixed image.\n",
    "    :return: Transformed moving image and the transformation parameter map.\n",
    "    \"\"\"\n",
    "    elastix_image_filter = sitk.ElastixImageFilter()\n",
    "    elastix_image_filter.SetFixedImage(fixed_image)\n",
    "    elastix_image_filter.SetMovingImage(moving_image)\n",
    "\n",
    "    # Get the default rigid registration parameter map\n",
    "    parameter_map = sitk.GetDefaultParameterMap(\"rigid\")\n",
    "    elastix_image_filter.SetParameterMap(parameter_map)\n",
    "\n",
    "    # Execute the registration\n",
    "    elastix_image_filter.Execute()\n",
    "\n",
    "    # Get the result image and the transformation parameter map\n",
    "    result_image = elastix_image_filter.GetResultImage()\n",
    "    transform_map = elastix_image_filter.GetTransformParameterMap()\n",
    "\n",
    "    return result_image, transform_map\n",
    "\n",
    "\n",
    "def apply_transform(moving_image, transform_map):\n",
    "    \"\"\"\n",
    "    Apply the transformation to the moving image using the given parameter map.\n",
    "    :param moving_image: Moving image to be transformed.\n",
    "    :param transform_map: Transformation parameter map.\n",
    "    :return: Transformed moving image.\n",
    "    \"\"\"\n",
    "    transformix_image_filter = sitk.TransformixImageFilter()\n",
    "    transformix_image_filter.SetMovingImage(moving_image)\n",
    "    transformix_image_filter.SetTransformParameterMap(transform_map)\n",
    "    transformix_image_filter.Execute()\n",
    "    return transformix_image_filter.GetResultImage()\n",
    "\n",
    "\n",
    "def get_image_type(image_path):\n",
    "    \"\"\"\n",
    "    Get the pixel type of the image\n",
    "    :param image_path: Path to the image\n",
    "    :return: Pixel type string\n",
    "    \"\"\"\n",
    "    image = sitk.ReadImage(image_path)\n",
    "    pixel_id = image.GetPixelID()\n",
    "    \n",
    "    if pixel_id == sitk.sitkUInt8:\n",
    "        return sitk.sitkUInt8\n",
    "    elif pixel_id == sitk.sitkUInt16:\n",
    "        return sitk.sitkUInt16\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported pixel type for image: {image_path}\")\n",
    "\n",
    "\n",
    "# Input image names\n",
    "image_names = [\n",
    "    \"T1_AF488\", \"T1_Cy3\", \"T1_Cy5\", \"T1_merge\",\n",
    "    \"T2_AF488\", \"T2_Cy3\", \"T2_Cy5\", \"T2_merge\",\n",
    "    \"T3_AF488\", \"T3_Cy3\", \"T3_Cy5\", \"T3_merge\"\n",
    "]\n",
    "\n",
    "# Directory where the input images are stored\n",
    "input_dir = \"D://FcTag decoding//1_input_image\"\n",
    "# Directory where the output images will be saved\n",
    "output_dir = \"D://FcTag decoding//2_image_registration\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Read the fixed image (T1_merge)\n",
    "fixed_image_name = \"T1_merge\"\n",
    "fixed_image_path = os.path.join(input_dir, f\"{fixed_image_name}.tif\")\n",
    "fixed_image_type = get_image_type(fixed_image_path)\n",
    "fixed_image = sitk.ReadImage(fixed_image_path, fixed_image_type)\n",
    "\n",
    "# Dictionary to store transformation parameter maps\n",
    "transformation_maps = {}\n",
    "\n",
    "# First align T2_merge and T3_merge to T1_merge\n",
    "for time_point in [2, 3]:\n",
    "    merge_image_name = f\"T{time_point}_merge\"\n",
    "    merge_image_path = os.path.join(input_dir, f\"{merge_image_name}.tif\")\n",
    "    \n",
    "    # Read image with original type\n",
    "    image_type = get_image_type(merge_image_path)\n",
    "    merge_image = sitk.ReadImage(merge_image_path, image_type)\n",
    "    \n",
    "    # Perform rigid registration\n",
    "    aligned_merge_image, transform_map = rigid_registration(fixed_image, merge_image)\n",
    "    \n",
    "    # Convert back to original type\n",
    "    aligned_merge_image = sitk.Cast(aligned_merge_image, image_type)\n",
    "    \n",
    "    # Save the aligned merge image\n",
    "    aligned_output_path = os.path.join(output_dir, f\"aligned_{merge_image_name}.tif\")\n",
    "    sitk.WriteImage(aligned_merge_image, aligned_output_path)\n",
    "    \n",
    "    # Store the transformation map for later use\n",
    "    transformation_maps[time_point] = transform_map\n",
    "\n",
    "# Apply transformations to AF488, Cy3, Cy5 channels using corresponding merge image transforms\n",
    "for time_point in [2, 3]:\n",
    "    # Get the transformation map from the corresponding merge image\n",
    "    transform_map = transformation_maps[time_point]\n",
    "    \n",
    "    # Apply the transformation to AF488, Cy3, Cy5 channels\n",
    "    for channel in [\"AF488\", \"Cy3\", \"Cy5\"]:\n",
    "        channel_image_name = f\"T{time_point}_{channel}\"\n",
    "        channel_image_path = os.path.join(input_dir, f\"{channel_image_name}.tif\")\n",
    "        \n",
    "        # Read image with original type\n",
    "        image_type = get_image_type(channel_image_path)\n",
    "        channel_image = sitk.ReadImage(channel_image_path, image_type)\n",
    "        \n",
    "        # Apply the transformation\n",
    "        aligned_channel_image = apply_transform(channel_image, transform_map)\n",
    "        \n",
    "        # Convert back to original type\n",
    "        aligned_channel_image = sitk.Cast(aligned_channel_image, image_type)\n",
    "        \n",
    "        # Save the aligned channel image\n",
    "        aligned_output_path = os.path.join(output_dir, f\"aligned_{channel_image_name}.tif\")\n",
    "        sitk.WriteImage(aligned_channel_image, aligned_output_path)\n",
    "\n",
    "print(\"Registration and transformation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Trim aligned images to the same size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This step is accomplished with the help of Fiji using the following Java code：\n",
    "- Fiji software can be downloaded from the [official Fiji software website](https://imagej.net/software/fiji/downloads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate a customized code: Open Fiji → Plugins → Macro → Record\n",
    "# To run the code: Open Fiji → Process → Batch → Macro\n",
    "# Input folder: D://FcTag decoding//3_Fiji_trim_input\n",
    "# Output folder: D://FcTag decoding//3_Fiji_trim_output\n",
    "//setTool(\"rectangle\");\n",
    "makeRectangle(60, 32, 960, 960);\n",
    "# To choose an appropriate size to crop: Open Fiji → open one of the image → choose Rectangle → the size will be shown in the software: x=4.18 (129), y=5.11 (315), w=0.50 (1024), h=0.46 (1024);\n",
    "# The cropped dimensions will be: 1024px* 1024px, as illustrated by the values w=0.50 (1024), h=0.46 (1024);\n",
    "run(\"Crop\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Extra color-changing information as one-dimensional array for each pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each pixel in the FcTag image, the color-changing information over different time points is stored in a one-dimensional array_m and displayed as follows: \n",
    "```\n",
    "array_m = np.array([T1_AF488, T1_Cy3, T1_Cy5, T2_AF488, T2_Cy3, T2_Cy5, T3_AF488, T3_Cy3, T3_Cy5])\n",
    "```\n",
    "\n",
    "- `T1_AF488`: AF488 channel obtained at time point 1 (0 min in this study)\n",
    "- `T1_Cy3`: Cy3 channel obtained at time point 1 (0 min in this study)\n",
    "- `T1_Cy5`: Cy5 channel obtained at time point 1 (0 min in this study)\n",
    "- `T2_AF488`: AF488 channel obtained at time point 2 (15 min in this study)\n",
    "- `T2_Cy3`: Cy3 channel obtained at time point 2 (15 min in this study)\n",
    "- `T2_Cy5`: Cy5 channel obtained at time point 2 (15 min in this study)\n",
    "- `T3_AF488`: AF488 channel obtained at time point 3 (30 min in this study)\n",
    "- `T3_Cy3`: Cy3 channel obtained at time point 3 (30 min in this study)\n",
    "- `T3_Cy5`: Cy5 channel obtained at time point 3 (30 min in this study)\n",
    "\n",
    "The color-changing information for each pixel is then stored in a worksheet, where the cell coordinates correspond to the pixel coordinates in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grayscale values have been exported to D://FcTag decoding//4_extra_color_information//color_changing_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# image file path\n",
    "image_files = [\n",
    "    'D://FcTag decoding//4_extra_color_information//T1_AF488.tif',\n",
    "    'D://FcTag decoding//4_extra_color_information//T1_Cy3.tif',\n",
    "    'D://FcTag decoding//4_extra_color_information//T1_Cy5.tif',\n",
    "    'D://FcTag decoding//4_extra_color_information//T2_AF488.tif',\n",
    "    'D://FcTag decoding//4_extra_color_information//T2_Cy3.tif',\n",
    "    'D://FcTag decoding//4_extra_color_information//T2_Cy5.tif',\n",
    "    'D://FcTag decoding//4_extra_color_information//T3_AF488.tif',\n",
    "    'D://FcTag decoding//4_extra_color_information//T3_Cy3.tif',\n",
    "    'D://FcTag decoding//4_extra_color_information//T3_Cy5.tif'\n",
    "]\n",
    "\n",
    "# create a new workbook\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Gray Values\"\n",
    "\n",
    "# create a dictionary to store the grayscale values of coordinates\n",
    "gray_value_dict = {}\n",
    "\n",
    "# iterate through each image file\n",
    "for image_file in image_files:\n",
    "    with Image.open(image_file) as img:\n",
    "        \n",
    "        # get image size\n",
    "        width, height = img.size\n",
    "        \n",
    "        # extract the grayscale value of each pixel\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                value = img.getpixel((x, y))\n",
    "                \n",
    "                # use the coordinates (x, y) as the key in the dictionary\n",
    "                if (x, y) not in gray_value_dict:\n",
    "                    gray_value_dict[(x, y)] = []\n",
    "                gray_value_dict[(x, y)].append(value)\n",
    "\n",
    "# write the grayscale values to the worksheet\n",
    "for (x, y), values in gray_value_dict.items():\n",
    "    # Combine grayscale values with the same coordinates into a one-dimensional array\n",
    "    combined_values = ', '.join(map(str, values))\n",
    "    ws.cell(row=y + 1, column=x + 1, value=combined_values)\n",
    "\n",
    "# write the grayscale values to the worksheet\n",
    "output_file = 'D://FcTag decoding//4_extra_color_information//color_changing_data.xlsx'\n",
    "wb.save(output_file)\n",
    "\n",
    "print(f\"grayscale values have been exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Linear unmixing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental concept of linear unmixing is based on the following formula:\n",
    "\n",
    " `array_m = C1*array_1 + C2*array_2 + …… + C27*array_27`\n",
    "\n",
    "- `array_m`：Color-changing information of each pixel.\n",
    "- `array_1` ~ `array_27`: Reference spectrum generated in section 5.\n",
    "- `contribution factor (C)`: Contribution of array_x in making up array_m, which also corresponds to the relative fluorescence intensity of the recontrasted image.\n",
    "- The match score, represented by the Mean Squared Error (MSE), can be fine-tuned to achieve optimal results. In our study, a threshold of MSE < 20 is applied, and values exceeding this threshold are deemed unreliable and excluded from analysis (i.e., set to zero). While these nullified pixels may slightly impact the visual quality of the decoded image, their effect on subsequent biological analyses is minimal and negligible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Linear unmixing of retianl proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import nnls\n",
    "import openpyxl\n",
    "\n",
    "# Read the color-changing information of each pixel\n",
    "input_df = pd.read_excel('D://FcTag decoding//5_linear_unmixing//color_changing_data.xlsx', header=None)\n",
    "\n",
    "# Spectrum-transforming fluorescent barcodes assigned to each protein\n",
    "arrays = [\n",
    "  np.array([0, 0, 1, 0, 0, 1, 1, 0, 0]), #1_β-Tubulin\n",
    "  np.array([0, 1, 0, 0, 1, 0, 1, 0, 0]), #2_Vimentin\n",
    "  np.array([1, 0, 0, 1, 0, 0, 0, 1, 0]), #3_PKC-α\n",
    "  np.array([0, 0, 1, 0, 0, 1, 0, 0, 1]), #4_Chx10\n",
    "  np.array([1, 0, 0, 0, 0, 1, 0, 1, 0]), #5_SV2\n",
    "  np.array([0, 0, 1, 0, 1, 0, 0, 1, 0]), #6_Synapsin\n",
    "]\n",
    "\n",
    "def find_combinations(array_m, arrays, max_arrays=6):\n",
    "    best_combination = None\n",
    "    best_constants = None\n",
    "    best_score = float('inf')\n",
    "\n",
    "    for n in range(1, max_arrays + 1):\n",
    "        for combo in combinations(enumerate(arrays), n):\n",
    "            indices, selected_arrays = zip(*combo)\n",
    "            \n",
    "            A = np.array(selected_arrays).T\n",
    "            b = array_m\n",
    "            try:\n",
    "                constants, _ = nnls(A, b)\n",
    "                predicted = np.dot(A, constants)\n",
    "                score = mean_squared_error(array_m, predicted)\n",
    "                \n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_combination = indices\n",
    "                    best_constants = constants\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    return best_combination, best_constants, best_score\n",
    "\n",
    "# Creat a new Excel file to store results\n",
    "workbook = openpyxl.Workbook()\n",
    "\n",
    "# Define the sheet with array and protein name\n",
    "sheet_names = ['1_Tubulin', '2_Vimentin', '3_PKC', '4_Chx10', '5_SV2', '6_Synapsin', 'Match Score']\n",
    "\n",
    "# Create an empty DataFrame for each sheet and fill it with 0.0\n",
    "results = {name: pd.DataFrame(0.0, index=input_df.index, columns=input_df.columns, dtype=float) for name in sheet_names}\n",
    "\n",
    "# Calculate the optimal combination for each cell\n",
    "for row in range(input_df.shape[0]):\n",
    "    for col in range(input_df.shape[1]):\n",
    "        cell_value = input_df.iloc[row, col]\n",
    "        if pd.notna(cell_value):  # Check if the cell is empty\n",
    "            array_m = np.array([float(x) for x in str(cell_value).split(',')])  # Convert the cell value to an array\n",
    "            if len(array_m) == len(arrays[0]):  # Ensure length matches\n",
    "                combination, constants, score = find_combinations(array_m, arrays)\n",
    "                \n",
    "                if score <= 20:\n",
    "                    for i, const in zip(combination, constants):\n",
    "                        results[sheet_names[i]].iloc[row, col] = const\n",
    "                \n",
    "                results['Match Score'].iloc[row, col] = score\n",
    "            else:\n",
    "                print(f\"Warning: Mismatch in array length at row {row+1}, column {col+1}\")\n",
    "\n",
    "# Write the results to Excel file\n",
    "with pd.ExcelWriter('D://FcTag decoding//5_linear_unmixing//contribution_factor.xlsx', engine='openpyxl') as writer:\n",
    "    for sheet_name, df in results.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)\n",
    "\n",
    "print(\"Results have been written to contribution_factor.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Linear unmixing of breast cancer proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to output_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import nnls\n",
    "import openpyxl\n",
    "\n",
    "# Read the Excel file (raw_data.xlsx)\n",
    "input_df = pd.read_excel('D://FcTag decoding//5_linear_unmixing//color_changing_data.xlsx', header=None)\n",
    "\n",
    "# color-changing barcode\n",
    "arrays = [\n",
    "  np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]), #01_CD3\n",
    "  np.array([1, 0, 0, 0, 0, 1, 0, 1, 0]), #02_CD4\n",
    "  np.array([0, 1, 0, 0, 0, 1, 1, 0, 0]), #03_CD8a\n",
    "  np.array([0, 0, 1, 0, 0, 1, 0, 1, 0]), #04_CD19\n",
    "  np.array([0, 1, 0, 1, 0, 0, 0, 0, 1]), #05_CD20\n",
    "  np.array([0, 1, 0, 0, 1, 0, 0, 0, 1]), #06_CD45RA\n",
    "  np.array([1, 0, 0, 0, 1, 0, 1, 0, 0]), #07_CD45RO\n",
    "  np.array([0, 1, 0, 0, 0, 1, 0, 0, 1]), #08_CD56\n",
    "  np.array([1, 0, 0, 0, 0, 1, 1, 0, 0]), #09_CD68\n",
    "  np.array([0, 0, 1, 1, 0, 0, 1, 0, 0]), #10_CD80\n",
    "  np.array([0, 0, 1, 0, 1, 0, 0, 1, 0]), #11_CD163\n",
    "  np.array([0, 1, 0, 0, 1, 0, 0, 1, 0]), #12_Foxp3\n",
    "  np.array([1, 0, 0, 1, 0, 0, 0, 1, 0]), #13_GZMB\n",
    "  np.array([0, 1, 0, 1, 0, 0, 1, 0, 0]), #14_MPO\n",
    "  np.array([0, 1, 0, 0, 0, 1, 0, 1, 0]), #15_PIP\n",
    "  np.array([0, 0, 1, 1, 0, 0, 0, 0, 1]), #16_HER2\n",
    "  np.array([1, 0, 0, 0, 0, 1, 0, 0, 1]), #17_CK56\n",
    "  np.array([1, 0, 0, 1, 0, 0, 0, 0, 1]), #18_CK19\n",
    "  np.array([0, 0, 1, 0, 1, 0, 1, 0, 0]), #19_EGFR\n",
    "  np.array([0, 0, 1, 0, 0, 1, 1, 0, 0]), #20_ER\n",
    "  np.array([0, 0, 1, 1, 0, 0, 0, 1, 0]), #21_PR\n",
    "  np.array([0, 0, 1, 0, 0, 1, 0, 0, 1]), #22_AR\n",
    "  np.array([1, 0, 0, 1, 0, 0, 1, 0, 0]), #23_Ki67\n",
    "  np.array([0, 1, 0, 0, 1, 0, 0, 1, 0]), #24_p63\n",
    "  np.array([0, 0, 1, 0, 1, 0, 0, 0, 1]), #25_CD31\n",
    "  np.array([1, 0, 0, 0, 1, 0, 0, 1, 0]), #26_SMA\n",
    "  np.array([0, 1, 0, 0, 1, 0, 1, 0, 0]), #27_PDPN\n",
    "]\n",
    "\n",
    "def find_combinations(array_m, arrays, max_arrays=4):\n",
    "    best_combination = None\n",
    "    best_constants = None\n",
    "    best_score = float('inf')\n",
    "\n",
    "    for n in range(1, max_arrays + 1):\n",
    "        for combo in combinations(enumerate(arrays), n):\n",
    "            indices, selected_arrays = zip(*combo)\n",
    "            \n",
    "            A = np.array(selected_arrays).T\n",
    "            b = array_m\n",
    "            try:\n",
    "                constants, _ = nnls(A, b)\n",
    "                predicted = np.dot(A, constants)\n",
    "                score = mean_squared_error(array_m, predicted)\n",
    "                \n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_combination = indices\n",
    "                    best_constants = constants\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    return best_combination, best_constants, best_score\n",
    "\n",
    "# Creat a new Excel file to store results\n",
    "workbook = openpyxl.Workbook()\n",
    "\n",
    "# Define the sheet with array and protein name\n",
    "sheet_names = ['01_CD3', '02_CD4', '03_CD8a', '04_CD19', '05_EGFR', '06_CD45RA', '07_CD45RO', '08_CD56', '09_CD68', \n",
    "               '10_CD80', '11_CD163', '12_Foxp3', '13_GZMB', '14_MPO', '15_PIP', '16_HER2', '17_CK56', '18_CK19', \n",
    "               '19_EGFR', '20_ER', '21_PR', '22_AR', '23_Ki67', '24_p63', '25_CD31', '26_SMA', '27_PDPN', 'Match Score']\n",
    "\n",
    "# Create an empty DataFrame for each sheet and fill it with 0.0\n",
    "results = {name: pd.DataFrame(0.0, index=input_df.index, columns=input_df.columns, dtype=float) for name in sheet_names}\n",
    "\n",
    "# Calculate the optimal combination for each cell\n",
    "for row in range(input_df.shape[0]):\n",
    "    for col in range(input_df.shape[1]):\n",
    "        cell_value = input_df.iloc[row, col]\n",
    "        if pd.notna(cell_value):  # Check if the cell is empty\n",
    "            array_m = np.array([float(x) for x in str(cell_value).split(',')])  # Convert the cell value to an array\n",
    "            if len(array_m) == len(arrays[0]):  # Ensure length matches\n",
    "                combination, constants, score = find_combinations(array_m, arrays)\n",
    "                \n",
    "                if score <= 20:\n",
    "                    for i, const in zip(combination, constants):\n",
    "                        results[sheet_names[i]].iloc[row, col] = const\n",
    "                \n",
    "                results['Match Score'].iloc[row, col] = score\n",
    "            else:\n",
    "                print(f\"Warning: Mismatch in array length at row {row+1}, column {col+1}\")\n",
    "\n",
    "# Write the results to Excel file\n",
    "with pd.ExcelWriter('D://FcTag decoding//5_linear_unmixing//contribution_factor.xlsx', engine='openpyxl') as writer:\n",
    "    for sheet_name, df in results.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)\n",
    "\n",
    "print(\"Results have been written to output_results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Linear unmixing based on biological prior knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we introduce prioritized marker combinations based on established knowledge of staining patterns. For instance, we prioritize the combination of array_1 (CD3), array_2 (CD4), and array_24 (CD45RA) for identifying naive CD4+ T cells. Our algorithm initially searches for optimal matches within these predefined, high-priority combinations. If no satisfactory matches are found (defined as combinations with a Mean Squared Error below 10), the algorithm expands its search beyond these initial constraints. Importantly, the Mean Squared Error threshold is adaptable and can be fine-tuned based on empirical results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import nnls\n",
    "import openpyxl\n",
    "\n",
    "# Read the Excel file (raw_data.xlsx)\n",
    "input_df = pd.read_excel('D://Linear unmixing//6_linear unmixing//raw_data.xlsx', header=None)\n",
    "\n",
    "# Reference spectrum (generated in section 5)\n",
    "arrays = [\n",
    "    np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]), #01_CD3\n",
    "    np.array([1, 0, 0, 0, 0, 1, 0, 1, 0]), #02_CD4\n",
    "    np.array([0, 1, 0, 0, 0, 1, 1, 0, 0]), #03_CD8a\n",
    "    np.array([0, 0, 1, 0, 0, 1, 0, 1, 0]), #04_CD19\n",
    "    np.array([0, 1, 0, 1, 0, 0, 0, 0, 1]), #05_CD20\n",
    "    np.array([0, 1, 0, 0, 1, 0, 0, 0, 1]), #06_CD45RA\n",
    "    np.array([1, 0, 0, 0, 1, 0, 1, 0, 0]), #07_CD45RO\n",
    "    np.array([0, 1, 0, 0, 0, 1, 0, 0, 1]), #08_CD56\n",
    "    np.array([1, 0, 0, 0, 0, 1, 1, 0, 0]), #09_CD68\n",
    "    np.array([0, 0, 1, 1, 0, 0, 1, 0, 0]), #10_CD80\n",
    "    np.array([0, 0, 1, 0, 1, 0, 0, 1, 0]), #11_CD163\n",
    "    np.array([0, 1, 0, 0, 1, 0, 0, 1, 0]), #12_Foxp3\n",
    "    np.array([1, 0, 0, 1, 0, 0, 0, 1, 0]), #13_GZMB\n",
    "    np.array([0, 1, 0, 1, 0, 0, 1, 0, 0]), #14_MPO\n",
    "    np.array([0, 1, 0, 0, 0, 1, 0, 1, 0]), #15_PIP\n",
    "    np.array([0, 0, 1, 1, 0, 0, 0, 0, 1]), #16_HER2\n",
    "    np.array([1, 0, 0, 0, 0, 1, 0, 0, 1]), #17_CK56\n",
    "    np.array([1, 0, 0, 1, 0, 0, 0, 0, 1]), #18_CK19\n",
    "    np.array([0, 0, 1, 0, 1, 0, 1, 0, 0]), #19_EGFR\n",
    "    np.array([0, 0, 1, 0, 0, 1, 1, 0, 0]), #20_ER\n",
    "    np.array([0, 0, 1, 1, 0, 0, 0, 1, 0]), #21_PR\n",
    "    np.array([0, 0, 1, 0, 0, 1, 0, 0, 1]), #22_AR\n",
    "    np.array([1, 0, 0, 1, 0, 0, 1, 0, 0]), #23_Ki67\n",
    "    np.array([0, 1, 0, 0, 1, 0, 0, 1, 0]), #24_p63\n",
    "    np.array([0, 0, 1, 0, 1, 0, 0, 0, 1]), #25_CD31\n",
    "    np.array([1, 0, 0, 0, 1, 0, 0, 1, 0]), #26_SMA\n",
    "    np.array([0, 1, 0, 0, 1, 0, 1, 0, 0]), #27_PDPN\n",
    "]\n",
    "\n",
    "# Prioritized protein combinations. The numbers enclosed in parentheses signify a potential combination. These numbers correspond to the array index minus one (e.g., 0 denotes array_1).\n",
    "specified_combinations = [\n",
    "    [(0,), (1,), (2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,), (14,), (15,), (16,), (17,), (18,), (19,), (20,), (21,), (22,), (23,), (24,), (25,), (26,)],\n",
    "    [(0, 1), (0, 23), (1, 23), (0, 1, 23), (0, 1), (0, 6), (1, 6), (0, 1, 6)],\n",
    "    [(8, 24)],\n",
    "    [(0, 2), (0, 23), (2, 23), (0, 2, 23)],\n",
    "    [(0, 2), (0, 6), (2, 6), (0, 2, 6)],\n",
    "    [(0, 2), (0, 18), (0, 23), (2, 18), (2, 23), (18, 23), (0, 2, 18), (0, 2, 23), (0, 18, 23), (2, 18, 23), (0, 2, 18, 23)],\n",
    "    [(0, 2), (0, 18), (0, 6), (2, 18), (2, 6), (18, 6), (0, 2, 18), (0, 2, 6), (0, 18, 6), (2, 18, 6), (0, 2, 18, 6)],\n",
    "    [(21, 3)],\n",
    "    [(7, 16), (7, 17), (7, 16, 17)],\n",
    "    [(24, 25)],\n",
    "    [(22, 5), (22, 26), (22, 24), (5, 26), (5, 24), (26, 24), (22, 5, 26), (22, 5, 24), (22, 26, 24), (5, 26, 24), (22, 5, 26, 24)],\n",
    "    [(9, 13), (9, 14), (9, 10), (9, 4), (13, 14), (13, 10), (13, 4), (14, 10), (14, 4), (10, 4)],\n",
    "    [(9, 13, 14), (9, 13, 10), (9, 13, 4), (9, 14, 10), (9, 14, 4), (9, 10, 4), (13, 14, 10), (13, 14, 4), (13, 10, 4), (14, 10, 4)],\n",
    "    [(9, 13, 14, 10), (9, 13, 14, 4), (9, 13, 10, 4), (9, 14, 10, 4), (13, 14, 10, 4)],\n",
    "    [(9, 13, 14, 10, 4)],\n",
    "    [(11, 12)]\n",
    "]\n",
    "\n",
    "def find_combinations(array_m, arrays, max_arrays=5):\n",
    "    best_combination = None\n",
    "    best_constants = None\n",
    "    best_score = float('inf')\n",
    "\n",
    "    # Searches for optimal matches within these predefined, high-priority combinations\n",
    "    specified_best_score = float('inf')\n",
    "    specified_best_combination = None\n",
    "    specified_best_constants = None\n",
    "    for combos in specified_combinations:\n",
    "        for combo in combos:\n",
    "            indices = combo\n",
    "            selected_arrays = [arrays[i] for i in indices]\n",
    "            A = np.array(selected_arrays).T\n",
    "            try:\n",
    "                constants, _ = nnls(A, array_m)\n",
    "                predicted = np.dot(A, constants)\n",
    "                score = mean_squared_error(array_m, predicted)\n",
    "                \n",
    "                if score <= 10 and score < specified_best_score:\n",
    "                    specified_best_score = score\n",
    "                    specified_best_combination = indices\n",
    "                    specified_best_constants = constants\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    if specified_best_combination is not None:\n",
    "        best_combination = specified_best_combination\n",
    "        best_constants = specified_best_constants\n",
    "        best_score = specified_best_score\n",
    "    else:\n",
    "        # If no satisfactory matches are found, the algorithm expands its search beyond these initial constraints\n",
    "        for n in range(1, max_arrays + 1):\n",
    "            for combo in combinations(enumerate(arrays), n):\n",
    "                indices, selected_arrays = zip(*combo)\n",
    "                A = np.array(selected_arrays).T\n",
    "                try:\n",
    "                    constants, _ = nnls(A, array_m)\n",
    "                    predicted = np.dot(A, constants)\n",
    "                    score = mean_squared_error(array_m, predicted)\n",
    "                    \n",
    "                    if score < best_score:\n",
    "                        best_score = score\n",
    "                        best_combination = indices\n",
    "                        best_constants = constants\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "    return best_combination, best_constants, best_score\n",
    "\n",
    "# Creat a new Excel file to store results\n",
    "workbook = openpyxl.Workbook()\n",
    "\n",
    "# Define the sheet with array and protein name\n",
    "sheet_names = ['01_CD3', '02_CD4', '03_CD8a', '04_CD19', '05_CD20', '06_CD45RA', '07_CD45RO', '08_CD56', '09_CD68', \n",
    "               '10_CD80', '11_CD163', '12_Foxp3', '13_GZMB', '14_MPO', '15_PIP', '16_HER2', '17_CK56', '18_CK19', \n",
    "               '19_EGFR', '20_ER', '21_PR', '22_AR', '23_Ki67', '24_p63', '25_CD31', '26_SMA', '27_PDPN', 'Match Score']\n",
    "\n",
    "# Create an empty DataFrame for each sheet and fill it with 0.0\n",
    "results = {name: pd.DataFrame(0.0, index=input_df.index, columns=input_df.columns, dtype=float) for name in sheet_names}\n",
    "\n",
    "# Use NumPy's vectorized operations to process input_df.\n",
    "input_array = input_df.to_numpy()\n",
    "for row in range(input_df.shape[0]):\n",
    "    for col in range(input_df.shape[1]):\n",
    "        cell_value = input_array[row, col]\n",
    "        if pd.notna(cell_value):  # Check if the cell is empty\n",
    "            array_m = np.array([float(x) for x in str(cell_value).split(',')])  # Convert the cell value to an array\n",
    "            if len(array_m) == len(arrays[0]):  # Ensure length matches\n",
    "                combination, constants, score = find_combinations(array_m, arrays)\n",
    "                \n",
    "                if score <= 100:\n",
    "                    for i, const in zip(combination, constants):\n",
    "                        results[sheet_names[i]].iloc[row, col] = const\n",
    "                \n",
    "                results['Match Score'].iloc[row, col] = score\n",
    "            else:\n",
    "                print(f\"Warning: Mismatch in array length at row {row+1}, column {col+1}\")\n",
    "\n",
    "# Write the results to Excel file\n",
    "with pd.ExcelWriter('D://Linear unmixing//6_linear unmixing//contribution_factor.xlsx', engine='openpyxl') as writer:\n",
    "    for sheet_name, df in results.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Image subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach to decode proteins from raw FcTag images is ‘image subtraction’. This method relies on maintaining consistent fluorescent intensities across different channels while avoiding overexposure, which is prerequisite for accurate target decoding. Based on this, when two images are merged, the fluorescence intensity of the combined image equals the sum of the intensities of the individual images (Image1+2 = Image1 + Image2). Conversely, by subtracting one image (Image1) from the merged image (Image1+2), the other image (Image2) can be resolved. These images can be any mathematically subtractable images, and the resolved image can also serve as a new base image for subsequent subtraction process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved image to: D://FcTag decoding//6_Image_subtraction\\01_SV2.tif\n",
      "Successfully saved image to: D://FcTag decoding//6_Image_subtraction\\02_Synapse.tif\n",
      "Successfully saved image to: D://FcTag decoding//6_Image_subtraction\\03_Tubulin.tif\n",
      "Successfully copied file: D://FcTag decoding//6_Image_subtraction\\T1_Cy3.tif -> D://FcTag decoding//6_Image_subtraction\\04_Vimentin.tif\n",
      "Successfully copied file: D://FcTag decoding//6_Image_subtraction\\T2_AF488.tif -> D://FcTag decoding//6_Image_subtraction\\05_PKC-α.tif\n",
      "Successfully copied file: D://FcTag decoding//6_Image_subtraction\\T3_Cy5.tif -> D://FcTag decoding//6_Image_subtraction\\06_Chx10.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def subtract_images(img_path1, img_path2, output_path):\n",
    "    \"\"\"Read two images, perform subtraction (only keep parts where img1 > img2), and save the result\"\"\"\n",
    "    # Read images\n",
    "    ImageC1 = cv2.imread(img_path1, cv2.IMREAD_GRAYSCALE)\n",
    "    ImageC2 = cv2.imread(img_path2, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if ImageC1 is None or ImageC2 is None:\n",
    "        print(f\"Error: Failed to read images. {img_path1} or {img_path2} does not exist\")\n",
    "        return False\n",
    "    \n",
    "    # Ensure both images have the same dimensions\n",
    "    if ImageC1.shape != ImageC2.shape:\n",
    "        print(f\"Error: Image dimensions do not match. {img_path1}: {ImageC1.shape}, {img_path2}: {ImageC2.shape}\")\n",
    "        return False\n",
    "    \n",
    "    # Get image dimensions\n",
    "    height, width = ImageC1.shape\n",
    "    \n",
    "    # Create an empty matrix to store new grayscale values\n",
    "    new_gray_values = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    # Traverse each pixel\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if ImageC1[i, j] > ImageC2[i, j]:\n",
    "                new_gray_values[i, j] = ImageC1[i, j] - ImageC2[i, j]\n",
    "            else:\n",
    "                new_gray_values[i, j] = 0\n",
    "    \n",
    "    # Save the result image\n",
    "    cv2.imwrite(output_path, new_gray_values)\n",
    "    print(f\"Successfully saved image to: {output_path}\")\n",
    "    return True\n",
    "\n",
    "def copy_and_rename_tif_file(source_file, target_file):\n",
    "    \"\"\"Copy and rename a TIF file while preserving metadata\"\"\"\n",
    "    try:\n",
    "        # Check if the source file exists\n",
    "        if not os.path.exists(source_file):\n",
    "            print(f\"Error: Source file {source_file} does not exist\")\n",
    "            return False\n",
    "        \n",
    "        # Check if the target file already exists\n",
    "        if os.path.exists(target_file):\n",
    "            print(f\"Error: Target file {target_file} already exists\")\n",
    "            return False\n",
    "        \n",
    "        # Create the directory for the target file if it doesn't exist\n",
    "        target_dir = os.path.dirname(target_file)\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy the file (preserves metadata)\n",
    "        shutil.copy2(source_file, target_file)\n",
    "        print(f\"Successfully copied file: {source_file} -> {target_file}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: An exception occurred during file copying: {e}\")\n",
    "        return False\n",
    "\n",
    "# Set the base directory\n",
    "base_dir = \"D://FcTag decoding//6_Image_subtraction\"\n",
    "\n",
    "# Perform image subtraction operations\n",
    "subtract_images(\n",
    "    os.path.join(base_dir, \"T1_AF488.tif\"),\n",
    "    os.path.join(base_dir, \"T2_AF488.tif\"),\n",
    "    os.path.join(base_dir, \"01_SV2.tif\")\n",
    ")\n",
    "\n",
    "subtract_images(\n",
    "    os.path.join(base_dir, \"T2_Cy3.tif\"),\n",
    "    os.path.join(base_dir, \"T1_Cy3.tif\"),\n",
    "    os.path.join(base_dir, \"02_Synapse.tif\")\n",
    ")\n",
    "\n",
    "subtract_images(\n",
    "    os.path.join(base_dir, \"T3_AF488.tif\"),\n",
    "    os.path.join(base_dir, \"T1_Cy3.tif\"),\n",
    "    os.path.join(base_dir, \"03_Tubulin.tif\")\n",
    ")\n",
    "\n",
    "# Perform file copying operations\n",
    "copy_and_rename_tif_file(\n",
    "    os.path.join(base_dir, \"T1_Cy3.tif\"),\n",
    "    os.path.join(base_dir, \"04_Vimentin.tif\")\n",
    ")\n",
    "\n",
    "copy_and_rename_tif_file(\n",
    "    os.path.join(base_dir, \"T2_AF488.tif\"),\n",
    "    os.path.join(base_dir, \"05_PKC-α.tif\")\n",
    ")\n",
    "\n",
    "copy_and_rename_tif_file(\n",
    "    os.path.join(base_dir, \"T3_Cy5.tif\"),\n",
    "    os.path.join(base_dir, \"06_Chx10.tif\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Image display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To assign the decoded image (grayscale) with `pseudo color`: Open zen 3.11 software → Dimensions → Channels.\n",
    "- To `merge images` of different proteins: Open zen 3.11 software → Processing → Method → Add channes.\n",
    "- zen 3.11 software can be downloaded from the [official Zeiss software website](https://www.zeiss.com/microscopy/zh/products/software/zeiss-zen.html).\n",
    "- The contribution factor decoded by linear unmixing can be displayed as a grayscale image (.tif) using the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for 8-bit image display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIFF image has been saved to D://FcTag decoding//7_image_display/01_CD3.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/02_CD4.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/03_CD8a.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/04_CD19.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/05_EGFR.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/06_CD45RA.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/07_CD45RO.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/08_CD56.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/09_CD68.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/10_CD80.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/11_CD163.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/12_Foxp3.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/13_GZMB.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/14_MPO.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/15_PIP.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/16_HER2.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/17_CK56.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/18_CK19.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/19_EGFR.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/20_ER.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/21_PR.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/22_AR.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/23_Ki67.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/24_p63.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/25_CD31.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/26_SMA.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/27_PDPN.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/Match Score.tif\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def excel_to_tiff(excel_path, output_dir):\n",
    "    # Open the Excel file\n",
    "    workbook = openpyxl.load_workbook(excel_path)\n",
    "\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        sheet = workbook[sheet_name]\n",
    "\n",
    "        # Get the dimensions of the Excel sheet\n",
    "        max_row = sheet.max_row\n",
    "        max_col = sheet.max_column\n",
    "\n",
    "        # Create a numpy array to store grayscale values, with data type np.uint8 (8-bit)\n",
    "        image_array = np.zeros((max_row, max_col), dtype=np.uint8)\n",
    "\n",
    "        # Read values from the Excel sheet and populate the array\n",
    "        for row in range(1, max_row + 1):\n",
    "            for col in range(1, max_col + 1):\n",
    "                cell_value = sheet.cell(row=row, column=col).value\n",
    "                if cell_value is not None:\n",
    "                    # Ensure the value is within the range of an 8-bit unsigned integer (0-255)\n",
    "                    cell_value = max(0, min(int(cell_value), 255))\n",
    "                    image_array[row - 1, col - 1] = cell_value\n",
    "\n",
    "        # Create an image with 8-bit mode ('L' for grayscale)\n",
    "        image = Image.fromarray(image_array, mode='L')\n",
    "\n",
    "        # Construct the output file path, naming it after the sheet name\n",
    "        tiff_path = f\"{output_dir}/{sheet_name}.tif\"\n",
    "\n",
    "        # Save the image as a TIFF file\n",
    "        image.save(tiff_path, format='TIFF')\n",
    "        print(f\"TIFF image has been saved to {tiff_path}\")\n",
    "\n",
    "# Specify the input Excel file path and output directory path\n",
    "excel_file_path = r\"D://FcTag decoding//7_image_display//contribution_factor.xlsx\"  # Replace with your Excel file path\n",
    "output_directory = r\"D://FcTag decoding//7_image_display\"  # Replace with the directory path where you want to save the TIFF files\n",
    "\n",
    "# Call the function\n",
    "excel_to_tiff(excel_file_path, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for 16-bit image display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIFF image has been saved to D://FcTag decoding//7_image_display/01_CD3.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/02_CD4.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/03_CD8a.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/04_CD19.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/05_EGFR.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/06_CD45RA.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/07_CD45RO.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/08_CD56.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/09_CD68.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/10_CD80.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/11_CD163.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/12_Foxp3.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/13_GZMB.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/14_MPO.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/15_PIP.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/16_HER2.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/17_CK56.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/18_CK19.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/19_EGFR.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/20_ER.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/21_PR.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/22_AR.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/23_Ki67.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/24_p63.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/25_CD31.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/26_SMA.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/27_PDPN.tif\n",
      "TIFF image has been saved to D://FcTag decoding//7_image_display/Match Score.tif\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def excel_to_tiff(excel_path, output_dir):\n",
    "    # Open the Excel file\n",
    "    workbook = openpyxl.load_workbook(excel_path)\n",
    "\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        sheet = workbook[sheet_name]\n",
    "\n",
    "        # Get the dimensions of the Excel sheet\n",
    "        max_row = sheet.max_row\n",
    "        max_col = sheet.max_column\n",
    "\n",
    "        # Create a numpy array to store grayscale values, with data type np.uint16\n",
    "        image_array = np.zeros((max_row, max_col), dtype=np.uint16)\n",
    "\n",
    "        # Read values from the Excel sheet and populate the array\n",
    "        for row in range(1, max_row + 1):\n",
    "            for col in range(1, max_col + 1):\n",
    "                cell_value = sheet.cell(row=row, column=col).value\n",
    "                if cell_value is not None:\n",
    "                    # Ensure the value is within the range of a 16-bit unsigned integer\n",
    "                    cell_value = max(0, min(int(cell_value), 65535))\n",
    "                    image_array[row - 1, col - 1] = cell_value\n",
    "\n",
    "        # Create an image\n",
    "        image = Image.fromarray(image_array, mode='I;16')\n",
    "\n",
    "        # Construct the output file path, naming it after the sheet name\n",
    "        tiff_path = f\"{output_dir}/{sheet_name}.tif\"\n",
    "\n",
    "        # Save the image as a TIFF file\n",
    "        image.save(tiff_path, format='TIFF')\n",
    "        print(f\"TIFF image has been saved to {tiff_path}\")\n",
    "\n",
    "# Specify the input Excel file path and output directory path\n",
    "excel_file_path = r\"D://FcTag decoding//7_image_display//contribution_factor.xlsx\"  # Replace with your Excel file path\n",
    "output_directory = r\"D://FcTag decoding//7_image_display\"  # Replace with the directory path where you want to save the TIFF files\n",
    "\n",
    "# Call the function\n",
    "excel_to_tiff(excel_file_path, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
